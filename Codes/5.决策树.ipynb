{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 第 5 章 决策树\n",
    "## 5.2 特 征 选 择\n",
    "### 算法 5.1 （信息增益的算法）\n",
    "![](https://qiniu.lianghao.work/markdown/20220505095834.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def readCsv(filepath):\n",
    "    D = []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            D.append(row)\n",
    "        f.close()\n",
    "    return D\n",
    "\n",
    "def extractFeatures(D):\n",
    "    '''从数据集中提取每个特征（包括分类）的不同取值'''\n",
    "    features = dict()\n",
    "    for i in range(0, len(D[0])):\n",
    "        tmp = []\n",
    "        for j in range(0, len(D)):\n",
    "            if D[j][i] not in tmp:\n",
    "                tmp.append(D[j][i])\n",
    "        if i != len(D[0]) - 1:\n",
    "            features['A' + str(i+1)] = tmp\n",
    "        else:\n",
    "            features['C'] = tmp\n",
    "    return features\n",
    "\n",
    "def calFeaturePa(featureId, featureVal, D):\n",
    "    '''统计每个特征不同取值的个数（如果除以总个数的话，就是分布了）'''\n",
    "    pa = dict()\n",
    "    for name in featureVal:\n",
    "        num = 0\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == name:\n",
    "                num += 1\n",
    "        pa[name] = num\n",
    "    return pa\n",
    "\n",
    "def entropy(pa):\n",
    "    '''计算概率分布的熵， pa为概率分布'''\n",
    "    sum = 0.0\n",
    "    for p in pa:\n",
    "        if p != 0:\n",
    "            sum += p * np.log2(p)\n",
    "        else:\n",
    "            sum += 0\n",
    "    return -1 * sum\n",
    "\n",
    "def conditionEntropy(featureName, featureId, Features, D):\n",
    "    '''计算条件熵'''\n",
    "    Y = Features['C']\n",
    "    pa_feature = calFeaturePa(featureId=featureId, featureVal=Features[featureName], D=D)\n",
    "    sum = 0.0\n",
    "    for x_i in Features[featureName]:\n",
    "        H_Y_xi = []\n",
    "        for y_i in Y:\n",
    "            tmp = 0\n",
    "            for i in range(0, len(D)):\n",
    "                if D[i][featureId] == x_i and D[i][len(D[0])-1] == y_i:\n",
    "                    tmp += 1\n",
    "            H_Y_xi.append(tmp / pa_feature[x_i])\n",
    "        sum += (pa_feature[x_i] / len(D)) * entropy(H_Y_xi)\n",
    "    return sum\n",
    "\n",
    "def gainInformation(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益\"\"\"\n",
    "    ConditionEntropy = conditionEntropy(featureName=featureName, featureId=featureId, Features=Features, D=D)\n",
    "    gi = entropY - ConditionEntropy\n",
    "    return gi\n",
    "\n",
    "def gainInformationRatio(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益比\"\"\"\n",
    "    gi = gainInformation(D=D, featureName=featureName, featureId=featureId, Features=Features, entropY=entropY)\n",
    "    featureClass = dict()\n",
    "    for i in range(0, len(D)):\n",
    "        if D[i][featureId] not in featureClass:\n",
    "            featureClass[D[i][featureId]] = 1\n",
    "        else:\n",
    "            featureClass[D[i][featureId]] += 1\n",
    "    featurPa = [val / len(D) for val in featureClass.values()]\n",
    "    gir = gi / entropy(featurPa)\n",
    "    return gir\n",
    "\n",
    "def selectBestFeatures(D, Features):\n",
    "    \"\"\"从当前数据集D和特征集A中根据信息增益选择最优特征\"\"\"\n",
    "    criterion = dict()\n",
    "    featureId = 0\n",
    "    entropY = entropy([val / len(D) for val in calFeaturePa(featureId=len(D[0])-1, featureVal=Features['C'], D=D).values()])\n",
    "    bestName = ''\n",
    "    bestVal = 0\n",
    "    for name in Features.keys():\n",
    "        if name != 'C':\n",
    "            # criterion[name] = gainInformation(D, name, featureId, Features, entropY)\n",
    "            criterion[name] = gainInformationRatio(D, name, featureId, Features, entropY)\n",
    "            featureId += 1\n",
    "            if bestVal < criterion[name]:\n",
    "                bestVal = criterion[name]\n",
    "                bestName = name\n",
    "    return bestName, bestVal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 例 5.2\n",
    "**对下表所给的训练数据集D，根据信息增益尊则选择最优的特征**\n",
    "![](https://qiniu.lianghao.work/markdown/20220505100016.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'A1': ['adolescent', 'middle', 'older'],\n 'A2': ['no', 'yes'],\n 'A3': ['no', 'yes'],\n 'A4': ['general', 'good', 'verygood'],\n 'C': ['no', 'yes']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取训练数据集D\n",
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "# 抽取特征集\n",
    "A = extractFeatures(D)\n",
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0.08300749985576883, 'A2': 0.32365019815155627, 'A3': 0.4199730940219749, 'A4': 0.36298956253708536}\n",
      "选择特征 A3 作为最优特征，其信息增益为0.42\n"
     ]
    }
   ],
   "source": [
    "# 计算各个特征的信息增益\n",
    "bestName, bestValue = selectBestFeatures(D, A)\n",
    "print(\"选择特征 {0} 作为最优特征，其信息增益为{1}\".format(bestName, round(bestValue, 4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 决策树的生成\n",
    "### 例 5.3 对下表中的训练数据集，利用ID3算法建立决策树\n",
    "![](https://qiniu.lianghao.work/markdown/20220505100016.png)\n",
    "生成的ID3决策树如下所示\n",
    "![](https://qiniu.lianghao.work/markdown/20220505202110.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def divDataSet(D, Feature, bestName):\n",
    "    featureId = 0\n",
    "    for key in Feature.keys():\n",
    "        if key == bestName:\n",
    "            break\n",
    "        featureId += 1\n",
    "    # div features\n",
    "    divD = dict()\n",
    "    for key in Feature[bestName]:\n",
    "        tmp = []\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == key:\n",
    "                D[i].pop(featureId)\n",
    "                tmp.append(D[i])\n",
    "        divD[key] = tmp\n",
    "    Feature.pop(bestName)\n",
    "    return divD, Feature\n",
    "\n",
    "def sampleClass(D):\n",
    "    clc = dict()\n",
    "    cid = len(D[0]) - 1\n",
    "    for i in range(0, len(D)):\n",
    "        if D[i][cid] not in clc:\n",
    "            clc[D[i][cid]] = 1\n",
    "        else:\n",
    "            clc[D[i][cid]] += 1\n",
    "    return clc\n",
    "\n",
    "def sameClass(D):\n",
    "    clc = sampleClass(D)\n",
    "    if len(clc.keys()) == 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def label(D):\n",
    "    clc = sampleClass(D)\n",
    "    maxn = ''\n",
    "    maxv = 0\n",
    "    for key, value in clc.items():\n",
    "        if maxv < value:\n",
    "            maxv = value\n",
    "            maxn = key\n",
    "    return maxn, maxv\n",
    "\n",
    "def showTree(parent, tree):\n",
    "    if tree == None:\n",
    "        return\n",
    "    print(parent, ' -- ', tree.relation, '  --', tree.value)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        showTree(tree.value, tree.children[i])\n",
    "\n",
    "def MakeGraph(parent, tree, g, idx):\n",
    "    if tree == None:\n",
    "        return\n",
    "    if idx > 1:\n",
    "        if 'A' not in tree.value:\n",
    "            g.node(name=parent+\" \"+tree.value)\n",
    "            g.edge(parent, parent+\" \"+tree.value, tree.relation)\n",
    "        else:\n",
    "            g.node(name=tree.value)\n",
    "            g.edge(parent, tree.value, tree.relation)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        MakeGraph(tree.value, tree.children[i], g, idx + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decision:\n",
    "    def __init__(self, value, relation):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        self.relation = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def ID3Tree(D, Feature, relation):\n",
    "    if sameClass(D) or len(Feature) == 1:\n",
    "        name, value = label(D)\n",
    "        return Decision(value=name, relation=relation)\n",
    "\n",
    "    bestName, bestValue = selectBestFeatures(D, Feature)\n",
    "    node = Decision(bestName, relation)\n",
    "    divd, divf = divDataSet(D, Feature, bestName)\n",
    "    Keys = [key for key in divd.keys()]\n",
    "    for i in range(0, len(Keys)):\n",
    "        # node.children.append(ID3Tree(divd[Keys[i]], divf, node.value))\n",
    "        node.children.append(ID3Tree(divd[Keys[i]], divf, Keys[i]))\n",
    "    return node\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "A = extractFeatures(D)\n",
    "root = ID3Tree(D, A, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None  --  None   -- A3\n",
      "A3  --  no   -- A2\n",
      "A2  --  no   -- no\n",
      "A2  --  yes   -- yes\n",
      "A3  --  yes   -- yes\n"
     ]
    }
   ],
   "source": [
    "showTree(None, root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'decisionTree.gv.pdf'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "# 创建对象\n",
    "g = Digraph('decisionTree')\n",
    "MakeGraph('start', root, g, 1)\n",
    "g.view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://qiniu.lianghao.work/markdown/20220505202110.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.5 CART算法\n",
    "### 5.5.1 CART树生成\n",
    "#### 例 5.4\n",
    "根据下表给定的训练数据集，应用**CART算法**生成决策树\n",
    "![](https://qiniu.lianghao.work/markdown/20220505100016.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def giNi(D):\n",
    "    \"\"\"计算Gini熵\"\"\"\n",
    "    clc = sampleClass(D)\n",
    "    N = len(D)\n",
    "    sum = 0.0\n",
    "    for key, value in clc.items():\n",
    "        sum += (value / N) ** 2\n",
    "    gini = 1 - sum\n",
    "    return gini\n",
    "\n",
    "def giniFeatureValue(D, FeatureId, FeatureValue):\n",
    "    \"\"\"根据特征A和其可能的值a计算其基尼指数\"\"\"\n",
    "    d1, d2 = [], []\n",
    "    for i in range(0, len(D)):\n",
    "        if D[i][FeatureId] == FeatureValue:\n",
    "            d1.append(D[i])\n",
    "        else:\n",
    "            d2.append(D[i])\n",
    "    gini = (len(d1) / len(D)) * giNi(d1) + (len(d2) / len(D)) * giNi(d2)\n",
    "    return gini\n",
    "\n",
    "def giniFeature(D, Features, FeatureName):\n",
    "    \"\"\"找到某一特征内的最优切分点\"\"\"\n",
    "    featureId = 0\n",
    "    for key in Features.keys():\n",
    "        if key == FeatureName:\n",
    "            break\n",
    "        featureId += 1\n",
    "    alpha = ''\n",
    "    maxgini = 1e10\n",
    "    for key in Features[FeatureName]:\n",
    "        gini = giniFeatureValue(D, featureId, key)\n",
    "        if maxgini > gini:\n",
    "            maxgini = gini\n",
    "            alpha = key\n",
    "    return maxgini, alpha\n",
    "\n",
    "def selectBestNode(D, Features):\n",
    "    \"\"\"找到最优特征和最优切分点\"\"\"\n",
    "    minName = ''\n",
    "    mingni = 1e10\n",
    "    alpha = ''\n",
    "    for featurName in Features.keys():\n",
    "        if featurName != 'C':\n",
    "            gini, nodeName = giniFeature(D, Features, featurName)\n",
    "            if mingni > gini:\n",
    "                minName = featurName\n",
    "                mingni = gini\n",
    "                alpha = nodeName\n",
    "    return minName, alpha, mingni"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class carTree:\n",
    "    \"\"\"CART树\"\"\"\n",
    "    def __init__(self, value, relation):\n",
    "        self.value = value\n",
    "        self.relation = relation\n",
    "        self.left = None\n",
    "        self.right = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def MakeCarTree(D, Feature, relation):\n",
    "    \"\"\"Cart 生成树\"\"\"\n",
    "    if sameClass(D) == True or len(Feature) == 1:\n",
    "        name, value = label(D)\n",
    "        return carTree(value=name, relation=relation)\n",
    "    bestFeatureName, bestNode, _ = selectBestNode(D, Feature)\n",
    "    node = carTree(value=bestFeatureName, relation=relation)\n",
    "    divd, divf = divDataSet(D, Feature, bestFeatureName)\n",
    "    node.right = MakeCarTree(divd[bestNode], divf, bestNode)\n",
    "    divd.pop(bestNode)\n",
    "    keys = [key for key in divd.keys()]\n",
    "    node.left = MakeCarTree(divd[keys[0]], divf, keys[0])\n",
    "    return node\n",
    "\n",
    "def showCarTree(parent, tree):\n",
    "    \"\"\"打印 Cart树\"\"\"\n",
    "    if tree == None:\n",
    "        return\n",
    "    print(parent, ' -- ', tree.relation, '  --', tree.value)\n",
    "    showCarTree(tree.value, tree.left)\n",
    "    showCarTree(tree.value, tree.right)\n",
    "\n",
    "def MakeCartGraph(parent, tree, g, idx):\n",
    "    \"\"\"制作生成树的图\"\"\"\n",
    "    if tree == None:\n",
    "        return\n",
    "    if idx > 1:\n",
    "        if 'A' not in tree.value:\n",
    "            g.node(name=parent+\" \"+tree.value)\n",
    "            g.edge(parent, parent+\" \"+tree.value, tree.relation)\n",
    "        else:\n",
    "            g.node(name=tree.value)\n",
    "            g.edge(parent, tree.value, tree.relation)\n",
    "    MakeCartGraph(tree.value, tree.left, g, idx + 1)\n",
    "    MakeCartGraph(tree.value, tree.right, g, idx + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "Features = extractFeatures(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "cartree = MakeCarTree(D, Features, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None  --  None   -- A3\n",
      "A3  --  yes   -- yes\n",
      "A3  --  no   -- A2\n",
      "A2  --  yes   -- yes\n",
      "A2  --  no   -- no\n"
     ]
    }
   ],
   "source": [
    "showCarTree(None, cartree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'carTree.gv.pdf'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "gCart = Digraph('carTree')\n",
    "MakeCartGraph('start', cartree, gCart, 1)\n",
    "gCart.view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://qiniu.lianghao.work/markdown/20220505211906.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 习题\n",
    "### 5.1 根据下表所给的训练数据集，利用**信息增益比 C4.5算法**生成决策树\n",
    "![](https://qiniu.lianghao.work/markdown/20220505100016.png)\n",
    "根据下列程序，可以得到C4.5决策树如下\n",
    "![](https://qiniu.lianghao.work/markdown/20220506103841.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "'''\n",
    "在ID3算法中，修改选择最优条件的函数selectBest， 将其中的准则（信息增益）替换成信息增益比\n",
    "'''\n",
    "def selectBestFeaturesRation(D, Features):\n",
    "    \"\"\"从当前数据集D和特征集A中根据信息增益选择最优特征\"\"\"\n",
    "    criterion = dict()\n",
    "    featureId = 0\n",
    "    entropY = entropy([val / len(D) for val in calFeaturePa(featureId=len(D[0])-1, featureVal=Features['C'], D=D).values()])\n",
    "    bestName = ''\n",
    "    bestVal = 0\n",
    "    for name in Features.keys():\n",
    "        if name != 'C':\n",
    "            # criterion[name] = gainInformation(D, name, featureId, Features, entropY)\n",
    "            criterion[name] = gainInformationRatio(D, name, featureId, Features, entropY)\n",
    "            featureId += 1\n",
    "            if bestVal < criterion[name]:\n",
    "                bestVal = criterion[name]\n",
    "                bestName = name\n",
    "    return bestName, bestVal\n",
    "\n",
    "def C45Tree(D, Feature, relation):\n",
    "    if sameClass(D) or len(Feature) == 1:\n",
    "        name, value = label(D)\n",
    "        return Decision(value=name, relation=relation)\n",
    "\n",
    "    bestName, bestValue = selectBestFeatures(D, Feature)\n",
    "    node = Decision(bestName, relation)\n",
    "    divd, divf = divDataSet(D, Feature, bestName)\n",
    "    Keys = [key for key in divd.keys()]\n",
    "    for i in range(0, len(Keys)):\n",
    "        # node.children.append(ID3Tree(divd[Keys[i]], divf, node.value))\n",
    "        node.children.append(ID3Tree(divd[Keys[i]], divf, Keys[i]))\n",
    "    return node"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "A = extractFeatures(D)\n",
    "root = C45Tree(D, A, None)\n",
    "from graphviz import Digraph\n",
    "# 创建对象\n",
    "g = Digraph('C4.5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None  --  None   -- A3\n",
      "A3  --  no   -- A2\n",
      "A2  --  no   -- no\n",
      "A2  --  yes   -- yes\n",
      "A3  --  yes   -- yes\n"
     ]
    }
   ],
   "source": [
    "showTree(None, root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "'C4.5.gv.pdf'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MakeGraph('start', root, g, 1)\n",
    "g.view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://qiniu.lianghao.work/markdown/20220506103841.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 根据下表中的训练数据， 试用平方误差损失准则生成一个二叉回归树\n",
    "![](https://qiniu.lianghao.work/markdown/20220506104214.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. 使用 sklearn 的 方法 对数据进行拟合"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "x = [i for i in range(1, 11)]\n",
    "y = [4.50,  4.75, 4.91, 5.34, 5.80, 7.05, 7.90, 8.23, 8.70, 9.00]\n",
    "# sklearn.tree 要求数据是二维的\n",
    "X = [[item] for item in x]\n",
    "Y = [[item] for item in y]\n",
    "# 创建 决策回归树\n",
    "regression = tree.DecisionTreeRegressor()\n",
    "# 对训练数据进行拟合\n",
    "regression.fit(X, Y)\n",
    "# 将训练好的回归树可视化\n",
    "dot_data = tree.export_graphviz(regression, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "# 保存到 iris.pdf中\n",
    "graph.render('iris')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.47.1 (20210417.1919)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1386pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 1386.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-473 1382,-473 1382,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"733,-469 574,-469 574,-401 733,-401 733,-469\"/>\n<text text-anchor=\"middle\" x=\"653.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 5.5</text>\n<text text-anchor=\"middle\" x=\"653.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 2.763</text>\n<text text-anchor=\"middle\" x=\"653.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"middle\" x=\"653.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 6.618</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"610,-365 451,-365 451,-297 610,-297 610,-365\"/>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.212</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 5.06</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M613.57,-400.88C602.39,-391.62 590.14,-381.45 578.55,-371.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"580.59,-368.99 570.66,-365.3 576.12,-374.38 580.59,-368.99\"/>\n<text text-anchor=\"middle\" x=\"572.98\" y=\"-386.49\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"853,-365 702,-365 702,-297 853,-297 853,-365\"/>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 7.5</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.46</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 8.176</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M693.76,-400.88C705.02,-391.62 717.38,-381.45 729.06,-371.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"731.52,-374.36 737.02,-365.3 727.07,-368.95 731.52,-374.36\"/>\n<text text-anchor=\"middle\" x=\"734.6\" y=\"-386.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"320,-261 161,-261 161,-193 320,-193 320,-261\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.028</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 4.72</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M450.87,-301.99C413.39,-288.81 368.53,-273.03 329.88,-259.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"330.8,-256.05 320.2,-256.03 328.47,-262.65 330.8,-256.05\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"610,-261 451,-261 451,-193 610,-193 610,-261\"/>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.053</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"530.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 5.57</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M530.5,-296.88C530.5,-288.78 530.5,-279.98 530.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"534,-271.3 530.5,-261.3 527,-271.3 534,-271.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"143,-149.5 0,-149.5 0,-96.5 143,-96.5 143,-149.5\"/>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 4.5</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.63,-192.88C165.31,-180.62 142.38,-166.78 122.43,-154.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"124.15,-151.69 113.78,-149.52 120.54,-157.68 124.15,-151.69\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"320,-157 161,-157 161,-89 320,-89 320,-157\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 2.5</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 4.83</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M240.5,-192.88C240.5,-184.78 240.5,-175.98 240.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"244,-167.3 240.5,-157.3 237,-167.3 244,-167.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"231,-53 88,-53 88,0 231,0 231,-53\"/>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 4.75</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M212.17,-88.95C204.41,-79.89 195.99,-70.07 188.2,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"190.73,-58.55 181.56,-53.24 185.41,-63.11 190.73,-58.55\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"392,-53 249,-53 249,0 392,0 392,-53\"/>\n<text text-anchor=\"middle\" x=\"320.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"320.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"320.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 4.91</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.48,-88.95C276.15,-79.89 284.46,-70.07 292.15,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"294.92,-63.13 298.71,-53.24 289.58,-58.61 294.92,-63.13\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"481,-149.5 338,-149.5 338,-96.5 481,-96.5 481,-149.5\"/>\n<text text-anchor=\"middle\" x=\"409.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"409.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"409.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 5.34</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M491.21,-192.88C477.26,-181.12 461.57,-167.89 447.7,-156.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"449.68,-153.29 439.77,-149.52 445.16,-158.64 449.68,-153.29\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"646,-149.5 499,-149.5 499,-96.5 646,-96.5 646,-149.5\"/>\n<text text-anchor=\"middle\" x=\"572.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = &#45;0.0</text>\n<text text-anchor=\"middle\" x=\"572.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"572.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 5.8</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M544.14,-192.88C548.62,-182 553.62,-169.86 558.15,-158.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"561.42,-160.1 561.99,-149.52 554.95,-157.43 561.42,-160.1\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"857,-261 698,-261 698,-193 857,-193 857,-261\"/>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 6.5</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.181</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"777.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 7.475</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M777.5,-296.88C777.5,-288.78 777.5,-279.98 777.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"781,-271.3 777.5,-261.3 774,-271.3 781,-271.3\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1129,-261 986,-261 986,-193 1129,-193 1129,-261\"/>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 8.5</text>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.1</text>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 8.643</text>\n</g>\n<!-- 10&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>10&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M853.27,-302.4C891.2,-288.58 937.15,-271.84 975.85,-257.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"977.33,-260.93 985.53,-254.22 974.93,-254.35 977.33,-260.93\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"807,-149.5 664,-149.5 664,-96.5 807,-96.5 807,-149.5\"/>\n<text text-anchor=\"middle\" x=\"735.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"735.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"735.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 7.05</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M763.86,-192.88C759.38,-182 754.38,-169.86 749.85,-158.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"753.05,-157.43 746.01,-149.52 746.58,-160.1 753.05,-157.43\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"968,-149.5 825,-149.5 825,-96.5 968,-96.5 968,-149.5\"/>\n<text text-anchor=\"middle\" x=\"896.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"896.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"896.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 7.9</text>\n</g>\n<!-- 11&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>11&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M816.14,-192.88C829.86,-181.12 845.29,-167.89 858.93,-156.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"861.41,-158.69 866.73,-149.52 856.86,-153.37 861.41,-158.69\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1129,-149.5 986,-149.5 986,-96.5 1129,-96.5 1129,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1057.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 8.23</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1057.5,-192.88C1057.5,-182.33 1057.5,-170.6 1057.5,-159.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1061,-159.52 1057.5,-149.52 1054,-159.52 1061,-159.52\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1306,-157 1147,-157 1147,-89 1306,-89 1306,-157\"/>\n<text text-anchor=\"middle\" x=\"1226.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 9.5</text>\n<text text-anchor=\"middle\" x=\"1226.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.023</text>\n<text text-anchor=\"middle\" x=\"1226.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1226.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 8.85</text>\n</g>\n<!-- 14&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>14&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1112.37,-192.88C1128.54,-183.12 1146.36,-172.37 1163.03,-162.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1164.86,-165.29 1171.62,-157.12 1161.25,-159.3 1164.86,-165.29\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1217,-53 1074,-53 1074,0 1217,0 1217,-53\"/>\n<text text-anchor=\"middle\" x=\"1145.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"1145.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1145.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 8.7</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1198.17,-88.95C1190.41,-79.89 1181.99,-70.07 1174.2,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1176.73,-58.55 1167.56,-53.24 1171.41,-63.11 1176.73,-58.55\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1378,-53 1235,-53 1235,0 1378,0 1378,-53\"/>\n<text text-anchor=\"middle\" x=\"1306.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"middle\" x=\"1306.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1306.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 9.0</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1254.48,-88.95C1262.15,-79.89 1270.46,-70.07 1278.15,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1280.92,-63.13 1284.71,-53.24 1275.58,-58.61 1280.92,-63.13\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1f9e867bb50>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 证明CART剪枝算法中，当$\\alpha$确定时，存在唯一的最小子树$T_\\alpha$使损失函数$C_\\alpha(T)$最小\n",
    "**解：由剪枝算法可得以下性质**：\n",
    "1. 剪枝只与内部结点$t$有关，当$C_\\alpha(t)<C_\\alpha(T_t)$时，对以结点$t$为根结点的子树$T_t$进行剪枝\n",
    "2. 假设剪枝前子树为$T_0$，剪枝后的子树为$T_t$，则$C\\alpha(T_t)\\ge C_\\alpha(T_0)$\n",
    "\n",
    "分别证明**存在性**和**唯一性**\n",
    "1. **存在性**：当$\\alpha$确定时，会生成多棵子树，一定存在损失函数最小的子树\n",
    "2. **唯一性**（反证法）：假设$\\alpha$确定时，存在两棵损失函数最小的子树$T_1,T_2$\n",
    "- 假设$T_1,T_2$子树相交（即结点$t_2$是$t_1$的子结点）：此时$T_1$子树是由对$T_2$剪枝得到的，因此存在唯一的子树使损失函数最小。\n",
    "- 假设$T_1,T_2$子树不相交（结点$t_1,t_2$是兄弟结点）：因为，$C_\\alpha(T_1)=C_\\alpha(T_2)$且最小，因此，可以对子树$T_1,T_2$进行剪枝，剪枝得到的子树为$T_3$，根据剪枝规则可得，$C_\\alpha(T_4)$最小，这与事实相悖，因此不存在两棵损失函数最小的子树。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 证明CART剪枝算法中求出的子树序列$\\{T_0,T_1,\\cdots,T_n\\}$分别是区间$\\alpha\\in[\\alpha_i,\\alpha_{i+1})$的最优子树$T_\\alpha$，其中$i=0,1,\\cdots,n,\\ 0=\\alpha_0<\\alpha_1<\\cdots<\\alpha_n<\\inf$\n",
    "[Reference](https://github.com/fengdu78/lihang-code/blob/master/%E7%AC%AC05%E7%AB%A0%20%E5%86%B3%E7%AD%96%E6%A0%91/5.DecisonTree.ipynb)\n",
    "**解**：\n",
    "1. $\\alpha=0$时，$C_\\alpha(T)=C(T)$，此时整体树$T_0$是最优的\n",
    "2. $\\alpha=+\\inf$时，此时，根节点组成的单结点树$T_n$是最优的\n",
    "3. $0\\le\\alpha<+\\inf$时：\n",
    "每次剪枝都是减去决策树以某个内部结点为根节点的子树，然后将这个内部结点作为叶结点进行保留。内部结点以外的其他结点是没有变化的，因此整体的损失函数时，只需要计算该内部结点局部的损失值的变化，即计算内部结点剪枝前后的损失函数。\n",
    "- 从整体树$T_0$进行剪枝，对$T_0$内部任意结点$t$\n",
    "- 剪枝前状态：有$T_t$个**叶子结点**，预测误差为$C(T_t)$，损失函数为$C_\\alpha(T_t)=C(T_t)+\\alpha|T_t|$\n",
    "- 剪枝后状态：只有一个叶子结点$t$，预测误差是$C(t)$，损失函数为$C_\\alpha(t)=C(t)+\\alpha$\n",
    "- 因此，存在一个$\\alpha$使得剪枝前后的损失值相等：$\\alpha=\\frac{C(t)-C(T_t)}{|T_t|-1}$\n",
    "- 找到了这个$\\alpha$就找到了待剪枝的内部结点$t$\n",
    "- 令$g(t)$表示剪枝后整体损失函数减少的程度，$g(t)=\\alpha$\n",
    "- 在$T(0)$中剪去$g(t)$最小的子树$T_t$，将得到的子树作为$T_1$，同时将最小的$g(t)=\\alpha_1$，此时，$T_1$为$[\\alpha_1,\\alpha_2)$的最优子树\n",
    "- 依次类推，子树$T_i$是$[\\alpha_i,\\alpha_{i+1})$的最优子树"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}