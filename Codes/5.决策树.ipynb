{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def readCsv(filepath):\n",
    "    D = []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            D.append(row)\n",
    "        f.close()\n",
    "    return D\n",
    "\n",
    "def extractFeatures(D):\n",
    "    '''从数据集中提取每个特征（包括分类）的不同取值'''\n",
    "    features = dict()\n",
    "    for i in range(0, len(D[0])):\n",
    "        tmp = []\n",
    "        for j in range(0, len(D)):\n",
    "            if D[j][i] not in tmp:\n",
    "                tmp.append(D[j][i])\n",
    "        if i != len(D[0]) - 1:\n",
    "            features['A' + str(i+1)] = tmp\n",
    "        else:\n",
    "            features['C'] = tmp\n",
    "    return features\n",
    "\n",
    "def calFeaturePa(featureId, featureVal, D):\n",
    "    '''统计每个特征不同取值的个数（如果除以总个数的话，就是分布了）'''\n",
    "    pa = dict()\n",
    "    for name in featureVal:\n",
    "        num = 0\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == name:\n",
    "                num += 1\n",
    "        pa[name] = num\n",
    "    return pa\n",
    "\n",
    "def entropy(pa):\n",
    "    '''计算概率分布的熵， pa为概率分布'''\n",
    "    sum = 0.0\n",
    "    for p in pa:\n",
    "        if p != 0:\n",
    "            sum += p * np.log2(p)\n",
    "        else:\n",
    "            sum += 0\n",
    "    return -1 * sum\n",
    "\n",
    "def conditionEntropy(featureName, featureId, Features, D):\n",
    "    '''计算条件熵'''\n",
    "    Y = Features['C']\n",
    "    pa_feature = calFeaturePa(featureId=featureId, featureVal=Features[featureName], D=D)\n",
    "    sum = 0.0\n",
    "    for x_i in Features[featureName]:\n",
    "        H_Y_xi = []\n",
    "        for y_i in Y:\n",
    "            tmp = 0\n",
    "            for i in range(0, len(D)):\n",
    "                if D[i][featureId] == x_i and D[i][len(D[0])-1] == y_i:\n",
    "                    tmp += 1\n",
    "            H_Y_xi.append(tmp / pa_feature[x_i])\n",
    "        sum += (pa_feature[x_i] / len(D)) * entropy(H_Y_xi)\n",
    "    return sum\n",
    "\n",
    "def gainInformation(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益\"\"\"\n",
    "    ConditionEntropy = conditionEntropy(featureName=featureName, featureId=featureId, Features=Features, D=D)\n",
    "    gi = entropY - ConditionEntropy\n",
    "    return gi\n",
    "\n",
    "def gainInformationRatio(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益比\"\"\"\n",
    "    ConditionEntropy = conditionEntropy(featureName=featureName, featureId=featureId, Features=Features, D=D)\n",
    "    gir = (entropY - ConditionEntropy) / ConditionEntropy\n",
    "    return gir\n",
    "\n",
    "def selectBestFeatures(D, Features):\n",
    "    \"\"\"从当前数据集D和特征集A中根据信息增益选择最优特征\"\"\"\n",
    "    criterion = dict()\n",
    "    featureId = 0\n",
    "    entropY = entropy([val / len(D) for val in calFeaturePa(featureId=len(D[0])-1, featureVal=Features['C'], D=D).values()])\n",
    "    bestName = ''\n",
    "    bestVal = 0\n",
    "    for name in Features.keys():\n",
    "        if name != 'C':\n",
    "            criterion[name] = gainInformation(D, name, featureId, Features, entropY)\n",
    "            featureId += 1\n",
    "            if bestVal < criterion[name]:\n",
    "                bestVal = criterion[name]\n",
    "                bestName = name\n",
    "    return bestName, bestVal\n",
    "\n",
    "def divDataSet(D, Feature, bestName):\n",
    "    featureId = 0\n",
    "    for key in Feature.keys():\n",
    "        print(featureId, key)\n",
    "        if key == bestName:\n",
    "            break\n",
    "        featureId += 1\n",
    "    # div features\n",
    "    divD = dict()\n",
    "    for key in Feature[bestName]:\n",
    "        tmp = []\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == key:\n",
    "                D[i].pop(featureId)\n",
    "                tmp.append(D[i])\n",
    "        divD[key] = tmp\n",
    "    Feature.pop(bestName)\n",
    "    return divD, Feature\n",
    "\n",
    "def showTree(parent, tree):\n",
    "    if tree == None:\n",
    "        return\n",
    "    print(parent, ' -- ', tree.relation, '  --', tree.value)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        showTree(tree.value, tree.children[i])\n",
    "\n",
    "def MakeGraph(parent, tree, g, idx):\n",
    "    if tree == None:\n",
    "        return\n",
    "    if idx > 1:\n",
    "        if 'A' not in tree.value:\n",
    "            g.node(name=parent+\" \"+tree.value)\n",
    "            g.edge(parent, parent+\" \"+tree.value, tree.relation)\n",
    "        else:\n",
    "            g.node(name=tree.value)\n",
    "            g.edge(parent, tree.value, tree.relation)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        MakeGraph(tree.value, tree.children[i], g, idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decision:\n",
    "    def __init__(self, value, relation):\n",
    "        self.value = value\n",
    "        self.children = None\n",
    "        self.relation = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def ID3Tree(D, Feature, relation):\n",
    "#     if SameClass(D) or len(Feature) == 1:\n",
    "#         name, value = GetMax(D)\n",
    "#         return Decision(value=name, relation=relation)\n",
    "#\n",
    "#     bestName, bestValue = selectBestFeatures(D, Feature)\n",
    "#     node = Decision(bestName, relation)\n",
    "#     divd, divf = divDataSet(D, Feature, bestName)\n",
    "#     Keys = [key for key in divd.Keys()]\n",
    "#     for i in range(0, len(Keys)):\n",
    "#         node.children.append(ID3Tree(divd[Keys[i]], divf, node.value))\n",
    "#     return node\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "A = extractFeatures(D)\n",
    "bestName, bestValue = selectBestFeatures(D, A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A1\n",
      "1 A2\n",
      "2 A3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "divd, divf = divDataSet(D, A, bestName)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}