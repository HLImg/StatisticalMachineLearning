

# 第1章 统计学习及监督学习概论

[例题与习题](https://github.com/aixiaoairen/StatisticalMachineLearning/blob/master/Codes/1.%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA.ipynb)：**<a href ="https://github.com/aixiaoairen/StatisticalMachineLearning/blob/master/Codes/1.%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA.ipynb"><img src="http://qiniu.lianghao.work/markdown/LiangH-StatiticalMachineLearning-blue"></a>**

## 1.1 统计学习([**Statistical learning**]())
### 1.1.1 统计学习的特点

**统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的一门学科。**统计学习也称为统计机器学习（[Statistical Machine Learning]()）。

Statistical Learning 具有以下的特点：

1. 建立在计算机以及网络之上
2. 以数据为研究对象，是数据驱动的学科
3. 目的是应用模型进行预测和分析
4. 以方法为中心，构建模型并应用模型进行预测与分析
5. 是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科。

### 1.1.2 统计学习的对象
**统计学习研究的对象是数据**。从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。

**统计学习关于数据的基本假设是同类数据（拥有共同性质的数据）具有一定的统计规律性，这是统计学习的前提。**

*说明：由于同类数据具有统计规律性，所以可以用概率统计方法处理他们。比如，使用随机变量描述数据中特征，用概率分布描述数据的统计规律。*

### 1.1.3 统计学习的目的

统计学习总的目标就是考虑**学习什么样的模型**和**如何学习模型**，以使模型能**对数据进行准确的预测与分析**，同时也要**尽可能地提高学习率**。

### 1.1.4 统计学习的方法

统计学习方法由**监督学习（supervised learning）**、**无监督学习（unsupervised learning）**和**强化学习（reinforcement learning）**等组成。

实现统计学习方法的步骤如下：

1. **得到一个有限的训练数据集合**：从给定的、有限的、用于学习的**训练数据（training data）集合**出发
2. **假设数据是独立同分布产生的**
3. **确定包含所有可能的模型的假设空间（hypothesis space）**: 学习模型属于某个函数的集合，称之为假设空间
4. **确定模型选择的准则，及学习的策略：**应用某个**评价准则（evaluation criterion）**，从假设空间中选择一个最优模型。
5. **实现求解最优模型的算法，及学习算法**
6. **通过学习算法选择最优模型：**从假设空间中选取一个最优模型，使它对已知的训练数据以及未知的**测试数据（test data）**在选择的**评价准则**下有最优模型。
7. **利用学习的最优模型对新数据进行预测或分析**

## 1.2 统计学习的分类

### 1.2.1 基本分类

#### 1.  监督学习（supervised learning）

监督学习是从**标注数据**中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。**监督学习的本质是学习输入到输出的映射的统计规律**。

##### （1）输入空间、特征空间和输出空间

1. 输入空间（input space）：输入所有可能取值的集合。
2. 输出空间（output space）：输出所有可能取值的集合。
3. 特征空间（feature space）：每个具体的输入是一个实例（instance），通常是特征向量（feature vector）表示，所有特征向量存在的空间成为特征空间。

在监督学习中，将输入和输出看作定义在输入空间和输出空间上的随机变量的取值。通常使用$X$表示输入变量，使用$Y$表示输出变量。输入和输出变量的取值分别使用对应的小写字母表示。

输入实例$x$的特征向量记作：
$$
x = (x^{(1)}, x^{(2)}, \cdots,x^{(i)}, \cdots, x^{(n)})^T
$$
*$x^{(i)}$表示$x$的第$i$个特征。$x_i$表示多个输入变量中的第$i$个向量，即$x_i=(x_1,x_2,cdots,x_i,cdots,x_n)^T$*。

训练数据由**输入（或特征向量）与输出组成**，训练集通常表示为
$$
T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}
$$
测试数据也由输入和输出组成。输入和输出对又称为样本（sample）或样本点。

**注：输入变量X和输出变量Y有不同的类型（连续或离散），根据输入和输出变量不同类型，对预测任务给与不同名称：**

(1)  **回归问题**： 输入（连续） ----->  输出（连续）

(2)  **分类问题**：输入（连续或离散）-----> 输出（离散）

(3)  **标注问题**：输入（*变量序列*）-----> 输出（*变量序列*）

##### （2）联合概率分布

监督学习假设输入和输出的随机变量$X,Y$遵循联合概率分布$P(X,Y)$。$P(X,Y)$表示分布函数或分布密度函数。

**注意：在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的，训练数据与测试数据被看作依联合概率分布$p(X,Y)$独立同分布产生的。**

##### （3）假设空间

监督学习的**目的在于学习一个由输入到输出的映射**，这一映射由模型来表示。

监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数（decision function）$Y=f(X)$表示。对具体的输入进行相应的输出预测时，写作$P(y|x) \ or \ y=f(x)$。

##### （4）问题的形式化

![](http://qiniu.lianghao.work/markdown/image-20220410170033680.png)

监督学习分为**学习**和**预测**两个过程。

1. 学习过程：学习系统利用给定的训练集，通过学习得到一个模型，表示为条件概率$\hat P(Y|X)$或者决策函数$Y=\hat f(X)$。
2. 预测过程：预测系统对于给定的训练样本集中的输入$x_{N+1}$，由学习得到的模型给出预测的输出$y_{N+1}$。

*一个有很好预测能力的模型，其训练样本输出$y_i$和模型输出$f(x_i)$之间的差值应该足够小。*

#### 2. 无监督学习（unsupervised learning）

无监督学习是指**从无标注数据中学习预测模型**的机器学习问题。*无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率*。**无监督学习的本质是学习数据中的统计规律或潜在结构**。

假设$X$是输入空间，$Z$是隐式结构空间。要学习的模型可以表示为函数$z=g(x)$，条件概率分布$P(z|x)$或者条件概率分布$P(x|z)$的形式。其中$x \in X$是输入，$z\in Z$是输出，包含所有可能的模型的集合称为假设空间。**无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。**

![image-20220410173312690](http://qiniu.lianghao.work/markdown/image-20220410173312690.png)

#### 3. 强化学习（reinforcement learning）

强化学习是指**智能系统与环境的连续互动中学习最优学习策略**的机器学习问题。假设智能系统与环境的互动基于**马尔卡夫决策过程（Markov dicision process）**，智能系统能观测到的是与环境互动得到的数据序列。**强化学习的本质是学习最优的序贯决策。**

在每一步$t$中，智能系统从环境中观测到一个**状态（state）$s_t$**与一个**奖励（reward）$r_t$**，采取一个**动作（action）$a_t$**。环境根据智能系统选择的动作，决定下一步$t+1$的状态$s_{t+1}$与奖励$r_{t+1}$。要学习的策略表示为给定的状态下采取的动作。**智能系统的目标不是短期奖励的最大化，而是长期累积奖励的最大化。** *在强化学习过程中，智能系统不断地试错（trial and error），以达到学习最优策略的目的。*

![image-20220410173733152](http://qiniu.lianghao.work/markdown/image-20220410173733152.png)

强化学习的马尔科夫决策过程是状态、奖励、动作序列上的随机过程，由五元组$<S, A, P, r,\gamma>$组成。

- S：state的集合

- A：action的集合

- P：状态转移概率（transition probability）函数：
  $$
  P(s'|s,a)=P(s_{t+1}=s'|s_t=s,a_t=a)
  $$

- $r$：奖励函数（reward function）$r(s,a)=E(r_{t+1}|s_t=s,a_t=a)$

- $\gamma$：衰减函数（discount factor）$\gamma \in [0, 1]$

*马尔可夫决策过程具有**马尔可夫性**，下一个状态只依赖于前一个状态与动作，由状态转移概率函数$P(s'|s,a)$表示，一个奖励依赖于前一个状态与动作，由奖励函数$r(s,a)表示$*。

策略$\pi$定义为给定状态下动作的函数$a=f(s)$或条件概率分布$P(a|s)$。给定一个策略$\pi$，智能系统与环境互动的动作的行为就以确定（或者是确定的或者是随机性的）。

==状态价值函数==（state value function）或价值函数（value function）**定义为策略$\pi$从一个状态$s$开始的长期累积奖励的数学期望：**
$$
v_\pi(s)=E_\pi[r_{t+1}+\gamma\cdot r_{t+2}+\gamma^2\cdot r_{t+3}+\cdots|s_t=s]
$$
==动作价值函数==（action value function）**定义为从策略$\pi$的从某一个状态$s$和动作$a$开始的长期累积奖励的数学期望：**
$$
q_\pi(s,a)=E_\pi[r_{t+1}+\gamma\cdot r_{t+2}+\gamma^2\cdot r_{t+3}+\cdots|s_t=s, a_t=a]
$$
**强化学习的目标就是在所有可能的策略中选出价值函数**，而在实际学习中往往从具体的策略出发，不断优化已有策略，**这里$\gamma$表示未来的奖励会有衰减。**

**强化学习方法中有基于策略（policy-based）、基于价值的（value-based），这两者属于无模型的（model-free）方法，还有基于模型的（model-based）方法。**

1. *有模型的*方法试图**直接学习马尔可夫决策过程的模型**，包括转移概率函数$P(s'|s, a)$和奖励函数$r(s,a)$。这样可以通过模型对环境的反馈进行预测，求出**价值函数最大的策略$\pi^*$**。
2. *无模型的、基于策略的*方法**不直接学习模型，而是试图求解最优策略$\pi^*$**，表示为函数$a=f^*(s)$或者是条件概率分布$P^*(a|s)$，这样也能达到在环境中最优策略的目的。**学习通过从一个具体策略出发，通过搜索更优的策略进行。**
3. *无模型、基于价值的*方法**也不直接学习模型，而是试图求解最优价值函数，特别是最优动作价值函数$q^*(s,a)$。**这样可以简介地学习最优策略，根据最优策略在给定的状态下做出相应的动作，**学习通常从一个具体价值函数开始，通过搜索更优的价值函数进行**。

#### 4. 半监督学习与主动学习

1. 半监督学习（semi-supervised leearning）指利用*标注数据*和*未标注数据*学习预测模型的机器学习问题。通常有**少量标注数据、大量未标注数据**。

2. 主动学习（active learning）指*机器不断主动给出实例让教师进行标注*，然后利用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往往是随机得到的，可以看作是“被动学习”，**主动学习的目标是找出对学习最优帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果**。

半监督学习和主动学习更接近监督学习。

### 1.2.2 按模型分类

#### 1. 概率模型与非概率模型

统计学习的模型可以分为**概率模型（probabilstic model）**和**非概率模型(non-probabilstic model)或者确定性模型(determinstic model)**。

| 注：$x$是输入，$y$是输出 | 监督学习 |      无监督学习      |
| :----------------------- | :------: | :------------------: |
| 概率模型                 | $P(y|x)$ | $P(y|x)\ or\ P(x|y)$ |
| 非概率模型               | $y=f(x)$ |       $z=g(x)$       |

*在监督学习中，概率模型是生成模型，非概率模型是判别模型。*

1. **常见的概率模型**：决策树、朴素贝叶斯、隐马尔可夫链、条件随机场、概率潜在语义分析、潜在狄利克雷分配、高斯混合模型。
2. **常见的非概率模型：**感知机、支持向量积、k近邻、AdaBost、k均值、潜在语义分析，以及神经网络。

**注**：

1. **逻辑斯谛回归既可看作概率模型，又可看作非概率模型**。
2. **条件概率分布通过最大化可以得到函数，函数归一化后可以得到条件概率分布。**
3. *概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而在于模型的内在结构。*概率模型一定可以表示为联合概率分布的形式，其中变量表示输入、输出、隐变量甚至参数，而针对非概率模型则不一定存在这样的联合概率分布。

概率模型的代表是**概率图模型（probabilistic graphical model）**，概率图模型是**联合概率分布**由**有向图或无向图**表示的概率模型。**联合概率可以根据下图的结构分解成因子乘积的形式**。其中**贝叶斯网络**、**马尔科夫随机场**、**条件随机场**都是概率图模型。无论模型多么复杂，均可以采用最基本的加法和乘法规则。![image-20220410212416059](http://qiniu.lianghao.work/markdown/image-20220410212416059.png)

#### 2. 线性模型和非线性模型

统计学习模型，特别是**非概率模型**，可以分为**线性模型（linear model）**和**非线性模型（non-linear model）**。

1. **常见的线性模型**：感知机、线性支持向量积、k近邻、k均值、潜在语义分析
2. **常见的非线性模型**：核函数支持向量积、AdaBoost、神经网络

#### 4. 参数化模型和非参数化模型

统计学习模型又可以分为**参数化模型（parametric model）**和**非参数模型（non-parametric model）**。

1. **参数化模型（parametric model）**：*假设模型参数的维度固定，模型可以由有限维参数完全刻画。*
2. **非参数模型（non-parametric model）**：*假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大*。

参数化模型适合问题简单的情况，复杂情况下，非参数模型更加有效。

### 1.2.3 按算法分类

| 在线学习（online learning） | 批量学习（batch learning） |
| :-------------------------: | :------------------------: |
|     每次只接受一个样本      |      一次接受所有数据      |

在线学习可以是监督学习，也可以是无监督学习。强化学习本身就拥有在线学习的特点。![image-20220410214006024](http://qiniu.lianghao.work/markdown/image-20220410214006024.png)

**利用随机梯度下降的感知机学习算法就是在线学习算法。**

### 1.2.4 按技巧分类

#### 1. 贝叶斯学习（Bayesian learning ）或贝叶斯推理（Bayesian inference）

**主要思想：在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并利用这个原理进行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用模型的先验分布是贝叶斯学习的特点。**

*朴素贝叶斯、潜在狄利克雷分配的学习*属于贝叶斯学习。

假设随机变量$D$表示数据，随机变量$\theta$表示模型参数。根据贝叶斯定理，可以计算以下后验概率$P(\theta|D)$：
$$
P(\theta|D)=\frac{P(D|\theta)\cdot P(\theta)}{P(D)}
$$
其中$P(\theta)$是先验概率，$P(D|\theta)$是似然函数。

**模型估计时，估计整个后验概率分布$P(\theta|D)$**，如果需要给出一个模型，通常取**后验概率最大模型**

**模型预测时，计算数据对后验概率分布的期望值：**
$$
P(x|D)=\int P(x|\theta,D)P(\theta|D)P(D)\  d\theta
$$
*注：这里的$x$是新样本。*

**贝叶斯估计**与**极大似然估计**在思想上有很大的不同，然而可以将二者简单地联系起来：*假设先验分布是均匀分布，取后验概率最大，就能从贝叶斯估计中得到极大似然估计*。

![image-20220411094645390](http://qiniu.lianghao.work/markdown/image-20220411094645390.png)

#### 2. 核方法（kernel method）

*核方法（kernel method）是使用核函数表示和学习**非线性模型**的一种机器学习方法。可以用于监督学习和无监督学习。*

对于一些基于*相似度或向量内积*计算的线性模型，*核方法可以把他们扩展到非线性模型的学习中，使其应用更加广泛。*

注：核函数支持向量机、核PCA、核k均值属于核方法。

**将线性模型扩展到非线性模型**，直接的做法是*显示地定义从输入空间（低维）到特征空间（高维）地映射，在特征空间进行内积计算*。例如，支持向量机，把输入空间的不可分问题转化为特征空间的线性可分问题。**核方法的技巧不在于显示地定义这个映射，而是定义整个核函数，即映射之后在特征空间的内积，这样可以简化计算，达到同样的效果。**

![image-20220411100722101](http://qiniu.lianghao.work/markdown/image-20220411100722101.png)

假设$x_1$和$x_2$是输入空间的任意两个实例（向量），其内积是$<x_1,x_2>$。假设从输入空间到特征空间的映射是$\varphi$，于是$x_1,x_2$在特征空间的映像是$\varphi(x_1),\varphi(x_2)$，其内积是$<\varphi(x_1),\varphi(x_2)>$。**核方法是直接在输入空间中定义核函数$K(x_1,x_2)$，使其满足$K(x_1,x_2)=<\varphi(x_1),\varphi(x_2)>$，表示定理给出核函数技巧成立的充分必要条件**。

## 1.3 统计学习方法三要素

统计学习方法都是由**模型、策略和算法构成的**。

### 1.3.1 模型（Model）

在监督学习中，**模型就是所要学习的条件概率分布或决策函数**。模型的**假设空间（hypothesis space）**包含**所有可能的条件概率分布或决策函数**。

假设空间（hypothesis space）使用$F$表示，假设空间可以定义为决策函数的集合：
$$
F=\{f|Y=f(X)\}
$$
其中$X,Y$分别是定义在输入空间，输出空间上的随机变量。*$F$通常是由一个参数向量决定的函数族：*

|               决策函数               |              条件概率分布               |
| :----------------------------------: | :-------------------------------------: |
| $F={f|Y=f_\theta(X),\theta \in R^n}$ | $F=\{P|Y=P_\theta(Y|X),\theta\in R^n\}$ |

**参数向量$\theta$取决于$n$维欧式空间$R^n$，称之为参数空间（parameter space）**。

### 1.3.2 策略

**统计学习的目标在于从假设空间中选取最优模型**。

#### 1. 损失函数和风险函数

**损失函数（loss function）或代价函数（cost function）**用于度量模型一次预测的好坏，即*度量模型预测错误的程度*，**损失函数是预测值$f(X)$和真实值$Y$的非负实值函数，记作$L(Y,f(X))$**。

统计学习常用的损失函数如下：

##### （1）0-1损失函数（0-1 loss function）

$$
L(Y,f(X))=\left\{ \begin{array}{l}
1,\ Y\neq f(X)\\
0,\ Y=f(X) 
\end{array} \right.
$$

##### (2) 平均损失函数（quadratic loss function）

$$
L(Y,f(X))=(Y - f(X))^2
$$

##### (3) 绝对损失函数（absolute loss function）

$$
L(Y,f(X))=|Y - f(X)|
$$

##### (4) 对数损失函数（log-likelihood loss function）

$$
L(Y,P(Y|X))=-\log P(Y|X)
$$

**损失函数越小，模型就越好。**由于模型的输入、输入$(X,Y)$是随机变量，遵循联合分布$P(X,Y)$，所以**损失函数的期望是：**
$$
\begin{aligned}
R_{\exp}(f) &= E_p[L(Y,f(X))]\\
&=\int_{X \times Y }L(y,f(x))P(x,y)\ dxdy
\end{aligned}
$$
这是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，称为**风险函数（risk function）或 期望损失（expected loss）**。

**学习的目标就是选择期望风险最小的模型**。由于联合分布$P(X,Y)$是未知的，期望损失无法直接计算，而*学习*又需要计算期望损失，所以监督学习就成为了一个病态问题（ill-formed problem）。

给定训练集:    $T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$

**模型$f(X)$关于训练集的平均损失称为经验风险（empirical risk）或经验损失（empirical loss），记作$R_{emp}$**
$$
R_{emp}(f)=\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))
$$
**期望风险（expected risk）和经验风险（empirical risk）的区别与联系**：

1. *期望风险是模型关于联合分布的期望损失*
2. *经验风险$R_{emp}(f)$是模型关于训练样本集的平均损失*
3. 根据**大数定律**，当样本容量$N$趋于无穷时，经验风险$R_{emp}(f)$趋于期望风险$R_{exp}(f)$
4. 根据3，经常使用经验风险来估计期望风险：**经验风险最小化**和**结构风险最小化**

#### 2. 经验风险最小化与结构风险最小化

##### （1）经验风险最小化（empirical risk minimization， ERM）

$$
\mathop {min}\limits_{f\in F}\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))
$$

**当样本容量$N$足够大时，经验风险最小化能保证有很好的学习效果**，在现实中被广泛采用，例如**极大似然估计**，当*模型是条件概率分布、损失函数是对数损失函数*时，**经验风险最小化就等于极大似然估计**。

****

**当样本容量很小时，经验风险最小化学习的效果未必很好，会产生“过拟合（over-fitting）”现象**。

##### （2）结构风险最小化（structural risk minimization, SRM）

为了防止**过拟合**而提出的策略，**结构风险最小化等价于正则化（regularization）**。*结构风险在经验风险上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）*。
$$
R_{srm}=\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))+\lambda J(f)
$$
其中$J(f)$为模型的复杂度，是定义在假设空间$F$上的泛函，模型$f$越复杂，复杂度$J(f)$就越大。**即复杂度表示了对复杂模型的惩罚**。$\lambda ≥ 0$是系数，用以权衡经验风险和模型复杂度。**结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测**。

*贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation, MAP）*是结构风险最小化的一个例子。当*模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示*时，**结构风险最小化就等价于最大后验概率估计**。
$$
\mathop {min}\limits_{f\in F}\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))+\lambda J(f)
$$


### 1.3.3 算法（algorithm）

**算法是指学习模型的具体计算方法，即需要什么样的计算方法求解最优模型**。

统计学习的算法称为求解最优化问题的算法。*当最优化问题有显示的解析解是，最优化问题较为简单*。*但通常解析解不存在，需要使用数值计算的方法求解，需要保证找到全局最优解，并且使求解过程非常高效。*

## 1.4 模型评估与模型选择

### 1.4.1 训练误差与测试误差

当损失函数给定时，基于损失函数的**训练误差（train error）**和**测试误差（test error）**成为了*学习方法评估的标准*。
$$
\begin{aligned}
R_{emp}(\hat f) &= \frac{1}{N}L(y_i, \hat f(x_i))\\
e_{test}(\hat f) &= \frac{1}{N'}L(y_i, \hat f(x_i))
\end{aligned}
$$
**测试误差反映了学习方法对未知的测试数据集的预测能力，测试误差小的方法有更好的预测能力**。通常*将学习方法对未知数据的预测能力*称为**泛化能力（generalization ability）**

### 1.4.2 过拟合和模型选择

**模型选择（model selection）应该在假设空间中选择最逼近“真”的模型，具体而言，所选择的模型要与真模型的参数个数相同，参数向量相近**。

如果一味追求对训练数据的预测能力，所选择模型的复杂度往往会比真模型更高，这种现象称为**过拟合（over-fitting）**。过拟合指**学习时选择的模型所包含的参数过多，以至于对已知数据预测得很好，但对未知数据预测得很差**。

因此，**模型选择旨在避免过拟合并提高模型的预测能力**。

为了防止**过拟合**，通常使用**正则化**和**交叉验证**这两种模型选择方法。

## 1.5 正则化与交叉验证

### 1.5.1 正则化（regularization）

模型选择的典型方法是正则化（regularization）。**正则化是结构风险最小化策略的实现**，正则化是在**经验风险最小化**的基础之上加上一个**正则化项（regularizer）**或**罚项（penalty term）**。正则化项一般是*模型复杂度的单调递增函数*。例如，正则化项可以是模型参数向量的范数。

正则化一般具有以下形式：
$$
\mathop {min}\limits_{f\in F}\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))+\lambda J(f)
$$
正则化项可以取不同的范数（L1范数，L2范数，），正则化项的作用是选择**经验风险与模型复杂度同时较小**的模型。从贝叶斯估计的角度来看，*正则化项对应于模型的先验概率*，可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。

### 1.5.2 交叉验证（cross validation）

如果给定的样本数据充足，进行模型选择的一种简单方法就是**随机地将数据集分成三个部分：**

1. **训练集（training set）**：训练模型
2. **验证集（validation set）**：选择模型
3. **测试集（test set）**：评估最终的学习方法

然而，实际应用中数据往往是不充足的，为了选择好的模型，可以采取**交叉验证**，交叉验证的**基本思想**是**重复地使用数据：把给定地数据进行切分，将切分地数据集组合成训练集与测试集，在此基础上反复地进行训练、测试和模型选择**。

1. **简单交叉验证**：*随机地将数据分成两部分：训练集（70%）和测试集（30%）*，然后用训练集在各种条件下训练模型，从而得到不同模型。在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
2. **S折交叉验证（S-fold cross validation）**：*随机地将数据切分为S个互补相交、大小相同的子集*，然后利用S-1个子集的数据进行训练，用余下的子集进行测试。*将这一过程对可能的S中选择重复进行*，最终选出S次评测中平均误差最小的模型。
3. **留一交叉验证（leave-one-out cross validation）**：这是**S折交叉验证的特殊情形，S=N**，这往往在数据缺乏的情况下使用。

## 1.6 泛化能力

### 1.6.1 泛化误差

学习方法的**泛化能力（generalization ability）**是指**该方法学习到的模型对未知数据的预测能力**。

现实中采用最多的方法是通过**测试误差**来评价学习方法的泛化能力，然而这种评价是基于测试数据集的，由于测试数据集是有限的，因此所得到的评价结果往往不可靠。

目前，统计学习理论试图从**理论上**对学习方法的泛化能力进行分析。

**如果学习到的模型是$\hat f$，那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）:**
$$
\begin{aligned}
R_{exp}(\hat f) &=E _P[L(Y, \hat f(X))]\\
&=\int_{X\times Y}L(y,\hat f(x))P(x, y)\ dxdy
\end{aligned}
$$
**泛化误差**反映了学习方法的**泛化能力**。事实上，*泛化误差就是所学习模型的的期望风险（损失）*。

### 1.6.2 泛化误差上界

学习方法的泛化能力分析往往是通过研究**泛化误差的概率上界**进行的，简称**泛化误差上界（generalization error bound）**。

泛化误差上界通常有以下**性质**：

1. *是样本容量$N$的函数*，$N$增加时，泛化上界趋于0
2. *是假设空间容量（capacity）的函数*，假设空间容量越大，模型就越难学习，泛化上界误差就越大

#### 定理 1.1 （泛化误差上界）

**对于二分类问题，当假设空间是有限个函数的集合，$F=\{f_1, f_2, \cdots, f_N\}$时，对任意一个函数$f\in F$，至少以概率$1-\var, 0 < \var < 1$，以下不等式成立**：
$$
R(f)\le \hat R(f) + \varepsilon(d, N, \var)
$$
其中
$$
\varepsilon(d, N, \var)=\sqrt{\frac{1}{2N}(\log d + \log \frac{1}{\var})}
$$
上述不等式的左端$R(f)$是**泛化误差**，右端是**泛化误差上界**。在泛化误差上界中，第1项$\hat R(f)$是训练误差，第2项$\varepsilon(d,N,\var)$是$N$的*单调递减函数*，同时也是$\sqrt{\log d}$阶的函数，假设空间$F$包含的函数越多，其值越大。

#### 证明 1.1 （泛化误差上界）

##### （1）霍夫丁（Hoeffding ）不等式的一般形式

**霍夫丁不等式给出了随机变量的和与其期望值偏差的概率上限**

**假设$X_1, X_2,\cdots,X_N \in R$是独立随机变量（注意：它们不一定服从同分布），假设他们是有限的，且$X_i \in [a_i, b_i], \ i=1,2,\cdots ,N$，将$X_1,X_2,\cdots,X_N$的经验均值记作$\bar X = \frac{1}{N}\sum_{i=1}^N X_i$，则对任意$t\ge 0$，以下不等式成立**：
$$
P(\bar X - E(\bar X) \ge t)\le \exp\{-\frac{2N^2t^2}{\sum_{i=1}^N(b_i-a_i)^2}\}
$$
**令$\bar X = -\bar X$，带入以上不等式，可得**：
$$
P(E(\bar X) - \bar X \ge t)\le \exp\{-\frac{2N^2t^2}{\sum_{i=1}^N(b_i-a_i)^2}\}
$$
**结合以上两式，即$|\bar X - E(\bar X)| = (\bar X - E(\bar X))\oplus(E(\bar X)-\bar X )$**，可得：
$$
P(|\bar X - E(\bar X)| \ge t)\le 2\exp\{-\frac{2N^2t^2}{\sum_{i=1}^N(b_i-a_i)^2}\}
$$

##### (2) Hoeffding不等式的应用——泛化误差上界

对任意函数$f \in F$, $\hat R(f)$是$N$个独立的随机变量$L(Y, f(X))$的*样本均值*，$R(f)$是随机变量$L(Y, f(X))$的*期望值*。如**损失函数（随机变量）$L(Y, f(X)) \in [0, 1]$**，即对所有随机变量，都有$[a_i, b_i]=[0,1]$，那么由Hoeffding不等式可以得到:
$$
P(R(f) - \hat R(f) \ge \varepsilon)\le \exp \{ -2 N \varepsilon^2 \}
$$
$F$是一个有限的集合，则有
$$
\begin{aligned}
P(\exist f \in F: R(f)-\hat R(f) \ge \varepsilon) &= P(\bigcup\limits_{\exist f \in F} \{R(f) -\hat R(f) \ge \varepsilon\} )\\
&\le \sum_{\forall f\in F}P(R(f)-\hat R(f) \ge \varepsilon)\\
& \le d\exp\{-2N\varepsilon^2\}
\end{aligned}
$$


因此，对$\forall f \in F$，有：
$$
P(\forall f \in F:R(f) - \hat R(f) < \varepsilon)\ge 1 -d\exp \{ -2 N \varepsilon^2 \}
$$
其中，$d$为假设空间中函数的个数，令$\var = d\exp\{-2N^2\varepsilon^2\}$，有
$$
P(R(f) <\hat R(f) + \varepsilon)\ge 1 -\var
$$
**即至少以概率$1-\var$有$R(f)<\hat R(f) + \var$**，从**泛化误差上界**可知：
$$
R(f_N)\le\hat R(f_N)+\varepsilon(d, N, \var)
$$
注：过程（27）主要是将**个体（不等式左边）**扩充到**整个假设空间中（不等式右边）**，因此才有该不等式的成立。

## 1.7 生成模型与判别模型

**监督学习的任务就是学习一个模型**，应用这一模型，对给定的输入预测相应的输出，**这个模型的一般形式为决策函数或条件概率分布**：
$$
Y = f(X)\\
P(Y|X)
$$
监督学习方法又可以分为**生成方法（generative approach）**和**判别方法（discriminative approach）**。所学到的模型分别称为*生成模型（generative model）*和*判别模型（discriminative model）*。

1. 生成方法：**由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型**：

$$
P(Y|X)=\frac{P(X,Y)}{P(X)}
$$

- 典型的生成模型有：*朴素贝叶斯法*和*隐马尔可夫模型*。
- **特点**：可以还原出$P(X,Y)$，判别方法不能。且*学习收敛速度快，存在隐变量时，仍可用生成方法学习，而判别方法就不能用*

2. 判别方法：**由数据直接学习决策函数$f(X)$或条件概率分布$P(Y|X)$作为预测的模型，即判别模型**

- 典型的判别模型：k近邻、感知机、决策树、最大熵、支持向量积、条件随机场等
- **特点**：直接学习的是$P(Y|X)$或$f(X)$，*学习的准确率更高，可以对数据进行各种程度上的抽象、定义特征并使用特征，可以简化学习问题*。

## 1.8 监督学习的应用

监督学习的应用主要在三个方面：**分类问题**、**标注问题**和**回归问题**。

### 1.8.1 分类问题（classification）

在监督学习中，当**输出变量$Y$取有限个离散值时**，预测问题便成为了分类问题。

监督学习从数据中学习一个**分类模型或分类决策函数**，称为**分类器（classifier）**。分类器对新的输入进行输出的预测，称为**分类（classification）**。可能的输出称为**类别（class）**.

 ![image-20220412122005320](http://qiniu.lianghao.work/markdown/image-20220412122005320.png)

评价分类器性能的指标一般是**分类准确率（accuracy）**，其定义是：**对于给定的测试数据集，分类器正确分类的样本数与总样本数之比**。另外还有**精确率（precision）**和**召回率（recall）**。

### 1.8.2 标注问题（tagging）

标注问题是分类问题的一个推广，标注问题**又是更复杂的结构预测（structure prediction）问题的简单形式**。标注问题的输入是一个**观测序列**，输出是一个**标记序列或状态序列**。标注问题的目标在于学习一个模型，使它**能够对观测序列给出标记序列作为预测**。

注：标记个数是有限的，但其组合成的标记序列的个数是依序列长度呈指数级增长的。

标注问题的训练集如下：
$$
T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}
$$
其中，输入观测序列：$x_i=(x^{(1)}_i,x^{(2)}_i,\cdots,x^{(n)}_i)^T$，输出标记序列序列：$x_i=(y^{(1)}_i,y^{(2)}_i,\cdots,y^{(n)}_i)^T$

![image-20220412122806764](http://qiniu.lianghao.work/markdown/image-20220412122806764.png)

标注常用的统计学习方法：隐马尔可夫模型、条件随机场。标注问题在*信息抽取、自然语言处理*等领域被广泛使用。

### 1.8.3 回归问题（regression）

监督学习中的回归问题用于**预测输入变量（自变量）和输出变量（因变量）之间的关系**。回归问题的学习等价于**回归函数的拟合**。

![image-20220412123436186](http://qiniu.lianghao.work/markdown/image-20220412123436186.png)
