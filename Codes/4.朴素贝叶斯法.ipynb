{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 第 4 章 朴素贝叶斯法\n",
    "## 4.2 朴素贝叶斯的参数估计\n",
    "### 例 4.1\n",
    "由下表的训练数据学习一个朴素贝叶斯分类器并*确定$x=(2, S)^T$的类标记$y$*。\n",
    "表中$X^{(1)},X^{(2)}$为特征，取值的集合分别为$A_1=\\{1,2,3\\},A_2=\\{S,M,L\\}$，$Y$为类标记，$Y \\in C =\\{1, -1\\}$\n",
    "![](https://qiniu.lianghao.work/markdown/20220416190900.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# 计算先验 P(Y=1)\n",
    "def Prior(C, Train_Y):\n",
    "    priors = dict()\n",
    "    for item in C:\n",
    "        sum = 0\n",
    "        for i in range(0, len(Train_Y)):\n",
    "            if Train_Y[i] == item:\n",
    "                sum = sum + 1\n",
    "        if item not in priors.keys():\n",
    "            priors[item] = sum\n",
    "    return priors\n",
    "\n",
    "def Joins(Train_X, Train_Y, A, C):\n",
    "    condition = dict()\n",
    "    for x in A:\n",
    "        for c in C:\n",
    "            sum = 0\n",
    "            for i in range(0, len(Train_X)):\n",
    "                if Train_X[i] == x and Train_Y[i] == c:\n",
    "                    sum = sum + 1\n",
    "            if (x, c) not in condition.keys():\n",
    "                condition[(x, c)] = sum\n",
    "    return condition\n",
    "\n",
    "def NaiveBayes(data, Train_X, Train_Y, A, C):\n",
    "    x1, x2 = data\n",
    "    # 计算朴素贝叶斯所需的概率\n",
    "    # 1. 先验概率\n",
    "    prior = Prior(C, Train_Y)\n",
    "    # 2. 条件概率概率\n",
    "    conditions = []\n",
    "    for i in range(0, len(Train_X)):\n",
    "        conditions.append(Joins(Train_X[i], Train_Y, A[i], C))\n",
    "    # 3. 计算后验\n",
    "    posterior = []\n",
    "    target = C[0]\n",
    "    max = -1\n",
    "    for item in C:\n",
    "        tmp = (prior[item] / len(Train_Y))\n",
    "        for i in range(0, len(data)):\n",
    "            tmp = tmp * (conditions[i][(data[i], item)] / prior[item])\n",
    "        # 寻找后验最大的类别\n",
    "        if max < tmp:\n",
    "            max = tmp\n",
    "            target = item\n",
    "    return target\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# 取值集合\n",
    "A1 = [1, 2, 3]\n",
    "A2 = ['S', 'M', 'L']\n",
    "C = [1, -1]\n",
    "# 训练数据\n",
    "X1 = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
    "X2 = ['S', 'M', 'M', 'S', 'S', 'S', 'M', 'M', 'L', 'L', 'L', 'M', 'M', 'L', 'L']\n",
    "Y = [-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1]\n",
    "data = [2, 'S']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 x : (2, S) 经过朴素贝叶斯算法分类后的结果为 ：y = -1\n"
     ]
    }
   ],
   "source": [
    "y =  NaiveBayes(data, [X1, X2], Y, [A1, A2], C)\n",
    "print(\"输入 x : ({0}, {1}) 经过朴素贝叶斯算法分类后的结果为 ：y = {2}\".format(data[0], data[1], y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 例 4.2\n",
    "由下表的训练数据学习一个朴素贝叶斯分类器并*确定$x=(2, S)^T$的类标记$y$*，使用拉普拉斯平滑估计概率，即$\\lambda=1$。\n",
    "表中$X^{(1)},X^{(2)}$为特征，取值的集合分别为$A_1=\\{1,2,3\\},A_2=\\{S,M,L\\}$，$Y$为类标记，$Y \\in C =\\{1, -1\\}$\n",
    "![](https://qiniu.lianghao.work/markdown/20220416190900.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# 计算先验 P(Y=1)\n",
    "def Prior(C, Train_Y, lam):\n",
    "    priors = dict()\n",
    "    for item in C:\n",
    "        sum = 0\n",
    "        for i in range(0, len(Train_Y)):\n",
    "            if Train_Y[i] == item:\n",
    "                sum = sum + 1\n",
    "        if item not in priors.keys():\n",
    "            priors[item] = (sum + lam) / (len(Train_Y) + len(C) * lam)\n",
    "    return priors\n",
    "\n",
    "def Joins(Train_X, Train_Y, A, C, lam):\n",
    "    condition = dict()\n",
    "    for x in A:\n",
    "        for c in C:\n",
    "            sum = 0\n",
    "            for i in range(0, len(Train_X)):\n",
    "                if Train_X[i] == x and Train_Y[i] == c:\n",
    "                    sum = sum + 1\n",
    "            sum_c = 0\n",
    "            for i in range(0, len(Train_Y)):\n",
    "                if Train_Y[i] == c:\n",
    "                    sum_c = sum_c + 1\n",
    "            if (x, c) not in condition.keys():\n",
    "                condition[(x, c)] = (sum + lam )/ (sum_c + len(A) * lam)\n",
    "    return condition\n",
    "\n",
    "def NaiveBayes(data, Train_X, A, Train_Y, C, lam):\n",
    "    x1, x2 = data\n",
    "    # 计算朴素贝叶斯所需的概率\n",
    "    # 1. 先验概率\n",
    "    prior = Prior(C, Train_Y, lam)\n",
    "    # 2. 条件概率概率\n",
    "    conditions = []\n",
    "    for i in range(0, len(Train_X)):\n",
    "        conditions.append(Joins(Train_X[i], Train_Y, A[i], C, lam))\n",
    "    # 3. 计算后验\n",
    "    target = C[0]\n",
    "    max = -1\n",
    "    for item in C:\n",
    "        tmp = prior[item]\n",
    "        for i in range(0, len(data)):\n",
    "            tmp = tmp * (conditions[i][(data[i], item)])\n",
    "        # 寻找后验最大的类别\n",
    "        print(tmp)\n",
    "        if max < tmp:\n",
    "            max = tmp\n",
    "            target = item\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# 取值集合\n",
    "A1 = [1, 2, 3]\n",
    "A2 = ['S', 'M', 'L']\n",
    "C = [1, -1]\n",
    "# 训练数据\n",
    "X1 = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
    "X2 = ['S', 'M', 'M', 'S', 'S', 'S', 'M', 'M', 'L', 'L', 'L', 'M', 'M', 'L', 'L']\n",
    "Y = [-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1]\n",
    "data = [2, 'S']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0326797385620915\n",
      "0.06100217864923746\n",
      "输入 x : (2, S) 经过朴素贝叶斯算法分类后的结果为 ：y = -1\n"
     ]
    }
   ],
   "source": [
    "y =  NaiveBayes(data, [X1, X2], [A1, A2], Y, C, 1)\n",
    "print(\"输入 x : ({0}, {1}) 经过朴素贝叶斯算法分类后的结果为 ：y = {2}\".format(data[0], data[1], y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 习题\n",
    "[Reference](https://blog.csdn.net/qq_41626059/article/details/115598863?spm=1001.2014.3001.5502)\n",
    "### 4.1 用极大似然估计法推出朴素贝叶斯法中的概率估计下列公式\n",
    "\\begin{aligned}\n",
    "P(Y=c_k) &=\\frac{\\sum_{i=1}^N I(y_i=c_k)}{N}\\\\\n",
    "P(X^{(j)}=a_{jl}|Y=c_k)&=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=a_k)}{\\sum_{i=1}^N I(y_i=c_k)}\n",
    "\\end{aligned}\n",
    "#### （1）先验概率的极大似然估计\n",
    "假设训练数据集$T=\\{(x_1, y_1),(x_2,y_2),\\cdots, (x_N, y_N)\\}$，其中训练集$T$中类别为$c_k$的数量为$n_k$，$P(y_i=c_k)=\\theta_k$。\n",
    "得到似然函数如下\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(y_1, y_2, \\cdots, y_N|\\theta_k) &= \\prod\\limits_{i=1}^N P(y_i|\\theta_k)\\\\\n",
    "&=\\theta_k^{n_k}(1-\\theta_k)^{(N-n_k)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "取对数并对参数求导可得\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta_k) &= n_k\\log \\theta_k+(N-n_k)\\log(1-\\theta_k)\\\\\n",
    "L'(\\theta_k) &= \\frac{n_k}{\\theta_k}-\\frac{N-\\theta_k}{1-\\theta_k}\n",
    "\\end{aligned}\n",
    "$$\n",
    "令导数$L'(\\theta_k)=0$，得当$\\theta_k = \\frac{n_k}{N}$时，似然函数取得最大值。\n",
    "由于$n_k = \\sum_{i=1}^N I(y_i=c_k)$，所以可得**先验概率**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^N I(y_=c_k)}{N}\n",
    "\\end{aligned}\n",
    "$$\n",
    "#### （2）条件概率的极大似然估计\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x^{(j)}=a_{jl}|Y=c_k)=\\frac{P(x^{(j)}=a_{jl}, Y=c_k)}{P(Y-c_k)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中，$P(Y-c_k)$就是前面推导出的先验概率，因此，只需要根据训练数据集推出联合概率分布$P(x^{(j)}=a_{jl}, Y=c_k)$即可。\n",
    "假设训练数据集$T=\\{(x_1, y_1),(x_2,y_2),\\cdots, (x_N, y_N)\\}$，其中$P(x^{(j)}=a_{jl}, Y=c_k)=\\theta$，并且满足$x^{(j)}=a_{jl}, Y=c_k$的数据个数为$n$。\n",
    "似然函数如下\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P((x^{(j)}_1, y_1), (x^{(j)}_2, y_2)l, \\cdots, (x^{(j)}_N, y_N)|\\theta) &= \\prod\\limits_{i=1}^N P((x^{(j)}_i, y_i))\\\\\n",
    "&=\\theta^n(1-\\theta)^{(N-n)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "对似然函数取对数并求导\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &= n\\log \\theta + (N-n)\\log(1-\\theta)\\\\\n",
    "L'(\\theta)&=\\frac{n}{\\theta} - \\frac{N-n}{1-\\theta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "当$\\theta = \\frac{n}{N}$时，似然函数取最大值。由于$n = \\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=ck)$，所以\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x^{(j)}=a_{jl}, Y=c_k) &= \\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=ck)}{N}\\\\\n",
    "P(x^{(j)}=a_{jl} | Y=c_k) &= \\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=ck)}{\\sum_{i=1}^N I(y_=c_k)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "### 4.2 用贝叶斯估计法推出朴素贝叶斯法中的概率估计下列公式\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P_\\lambda(Y=c_k)&=\\frac{\\sum_{i=1}^N I(y_i=c_k)+\\lambda}{N + K\\lambda}\\\\\n",
    "P_\\lambda(X^{(j)}=a_{jl}|Y=c_k)&=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i = c_k)+\\lambda}{\\sum_{i=1}^NI(y_i=c_k)+S_j\\lambda}\n",
    "\\end{aligned}\n",
    "$$\n",
    "#### （1）先验概率的贝叶斯估计\n",
    "假设训练数据集$T=\\{(x_1, y_1),(x_2,y_2),\\cdots, (x_N, y_N)\\}$，其中$P(y_i=c_k)=\\theta_k$，并且满足$Y=c_k$的数据个数为$n_k=\\sum_{i=1}^N P(y_i = c_k)$\n",
    "由于贝叶斯估计要引入待估计参数的先验信息，这里假设参数是均匀分布的，此外$Y$的取值个数为$K$个，即$Y\\in \\{c_1, c_2, \\cdots, c_K\\}$，所以$P(\\theta_k)=\\theta_k^\\lambda(1-\\theta_k)^{(K-1)\\lambda}$。其中，$Y$的取值有$K$种情况，$\\lambda$表示每种情况的初始值，即每种情况有$\\lambda$次发生\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(y_1, y_2, \\cdots, y_N | \\theta_k)\\cdotp(\\theta_k) &= \\prod\\limits_{i=1}^N P(y_i=c_k)\\cdot P(\\theta_k)\\\\\n",
    "&=\\theta_k^{n_k}(1-\\theta_k)^{(N - n_k)} * \\theta_k^\\lambda(1-\\theta_k)^{(K-1)\\lambda}\\\\\n",
    "&=\\theta_k^{n_k + \\lambda}(1-\\theta_k)^{N - n_k+(K-1)\\lambda}\n",
    "\\end{aligned}\n",
    "$$\n",
    "取对数，并求得可得$\\theta_k=\\frac{n_k+\\lambda}{N+K\\lambda}$，即\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=c_k)= \\frac{\\sum_{i=1}^N I(y_i=c_k)+\\lambda}{N +K\\lambda}\n",
    "\\end{aligned}\n",
    "$$\n",
    "#### （2）条件概率的贝叶斯估计\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x^{(j)}=a_{jl}|Y=c_k)=\\frac{P(x^{(j)}=a_{jl}, Y=c_k)}{P(Y-c_k)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中，$P(Y-c_k)$就是前面推导出的先验概率，因此，只需要根据训练数据集推出联合概率分布$P(x^{(j)}=a_{jl}, Y=c_k)$即可。\n",
    "假设训练数据集$T=\\{(x_1, y_1),(x_2,y_2),\\cdots, (x_N, y_N)\\}$，其中$P(x^{(j)}=a_{jl}, Y=c_k)=\\theta$，并且满足$x^{(j)}=a_{jl}, Y=c_k$的数据个数为$n$。参数$\\theta$先验信息， $P(\\theta)=\\theta^{\\lambda}(1-\\theta)^{(KS_j-1)\\lambda}$, $S_j$为$x^{(j)}$可取的情况，$K$为$y_i$可取的情况\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P((x^{(j)}_1, y_1), (x^{(j)}_2, y_2)l, \\cdots, (x^{(j)}_N, y_N)|\\theta) \\cdot P(\\theta) &= \\prod\\limits_{i=1}^N P((x^{(j)}_i, y_i)) \\cdot P(\\theta)\\\\\n",
    "&=\\theta^n(1-\\theta)^{(N-n)} \\cdot \\theta^{\\lambda}(1-\\theta)^{(KS_j-1)\\lambda}\\\\\n",
    "&=\\theta^{n + \\lambda}(1-\\lambda)^{N -n+(KS_j-1)\\lambda}\n",
    "\\end{aligned}\n",
    "$$\n",
    "取对数并求导\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &= (n+\\lambda)\\log \\theta + (\\lambda KS_j-\\lambda+N - n)\\log(1-\\theta)\\\\\n",
    "L'(\\theta) &=\\frac{n+\\lambda}{\\theta}-\\frac{\\lambda KS_j-\\lambda+N - n}{1-\\theta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "令导数为0，可得$\\theta = \\frac{n+\\lambda}{N+\\lambda KS_j}$，由于$n = \\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=c_k)$，所以\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x^{(j)}=a_{jl}, Y=c_k) = \\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda}{N + \\lambda KS_J}\n",
    "\\end{aligned}\n",
    "$$\n",
    "又加上$P(Y=c_k)= \\frac{\\sum_{i=1}^N I(y_i=c_k)+\\lambda}{N +K\\lambda}$，所以得贝叶斯估计的条件概率\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x^{(j)}=a_{jl}|Y=c_k) &=\\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda_0}{N + \\lambda_0 KS_J} \\cdot \\frac{N +K\\lambda_1}{\\sum_{i=1}^N I(y_i=c_k)+\\lambda_1}\\\\\n",
    "&= asume \\ \\ lambda_1 = S_j \\lambda_0\\\\\n",
    "&= \\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda_0}{N + \\lambda_0 KS_j} \\cdot \\frac{N +\\lambda_0 KS_j}{\\sum_{i=1}^N I(y_i=c_k)+\\lambda_0 S_j}\\\\\n",
    "& = \\frac{\\sum_{i=1}^N I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda_0}{\\sum_{i=1}^N I(y_i=c_k)+\\lambda_0 S_j}\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}