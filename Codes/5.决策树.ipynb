{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 第 5 章 决策树\n",
    "## 5.2 特 征 选 择\n",
    "### 算法 5.1 （信息增益的算法）\n",
    "![](http://qiniu.lianghao.work/markdown/20220505095834.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def readCsv(filepath):\n",
    "    D = []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            D.append(row)\n",
    "        f.close()\n",
    "    return D\n",
    "\n",
    "def extractFeatures(D):\n",
    "    '''从数据集中提取每个特征（包括分类）的不同取值'''\n",
    "    features = dict()\n",
    "    for i in range(0, len(D[0])):\n",
    "        tmp = []\n",
    "        for j in range(0, len(D)):\n",
    "            if D[j][i] not in tmp:\n",
    "                tmp.append(D[j][i])\n",
    "        if i != len(D[0]) - 1:\n",
    "            features['A' + str(i+1)] = tmp\n",
    "        else:\n",
    "            features['C'] = tmp\n",
    "    return features\n",
    "\n",
    "def calFeaturePa(featureId, featureVal, D):\n",
    "    '''统计每个特征不同取值的个数（如果除以总个数的话，就是分布了）'''\n",
    "    pa = dict()\n",
    "    for name in featureVal:\n",
    "        num = 0\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == name:\n",
    "                num += 1\n",
    "        pa[name] = num\n",
    "    return pa\n",
    "\n",
    "def entropy(pa):\n",
    "    '''计算概率分布的熵， pa为概率分布'''\n",
    "    sum = 0.0\n",
    "    for p in pa:\n",
    "        if p != 0:\n",
    "            sum += p * np.log2(p)\n",
    "        else:\n",
    "            sum += 0\n",
    "    return -1 * sum\n",
    "\n",
    "def conditionEntropy(featureName, featureId, Features, D):\n",
    "    '''计算条件熵'''\n",
    "    Y = Features['C']\n",
    "    pa_feature = calFeaturePa(featureId=featureId, featureVal=Features[featureName], D=D)\n",
    "    sum = 0.0\n",
    "    for x_i in Features[featureName]:\n",
    "        H_Y_xi = []\n",
    "        for y_i in Y:\n",
    "            tmp = 0\n",
    "            for i in range(0, len(D)):\n",
    "                if D[i][featureId] == x_i and D[i][len(D[0])-1] == y_i:\n",
    "                    tmp += 1\n",
    "            H_Y_xi.append(tmp / pa_feature[x_i])\n",
    "        sum += (pa_feature[x_i] / len(D)) * entropy(H_Y_xi)\n",
    "    return sum\n",
    "\n",
    "def gainInformation(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益\"\"\"\n",
    "    ConditionEntropy = conditionEntropy(featureName=featureName, featureId=featureId, Features=Features, D=D)\n",
    "    gi = entropY - ConditionEntropy\n",
    "    return gi\n",
    "\n",
    "def gainInformationRatio(D, featureName, featureId, Features, entropY):\n",
    "    \"\"\"计算信息增益比\"\"\"\n",
    "    ConditionEntropy = conditionEntropy(featureName=featureName, featureId=featureId, Features=Features, D=D)\n",
    "    gir = (entropY - ConditionEntropy) / ConditionEntropy\n",
    "    return gir\n",
    "\n",
    "def selectBestFeatures(D, Features):\n",
    "    \"\"\"从当前数据集D和特征集A中根据信息增益选择最优特征\"\"\"\n",
    "    criterion = dict()\n",
    "    featureId = 0\n",
    "    entropY = entropy([val / len(D) for val in calFeaturePa(featureId=len(D[0])-1, featureVal=Features['C'], D=D).values()])\n",
    "    bestName = ''\n",
    "    bestVal = 0\n",
    "    for name in Features.keys():\n",
    "        if name != 'C':\n",
    "            criterion[name] = gainInformation(D, name, featureId, Features, entropY)\n",
    "            featureId += 1\n",
    "            if bestVal < criterion[name]:\n",
    "                bestVal = criterion[name]\n",
    "                bestName = name\n",
    "    return bestName, bestVal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 例 5.2\n",
    "**对下表所给的训练数据集D，根据信息增益尊则选择最优的特征**\n",
    "![](http://qiniu.lianghao.work/markdown/20220505100016.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'A1': ['adolescent', 'middle', 'older'],\n 'A2': ['no', 'yes'],\n 'A3': ['no', 'yes'],\n 'A4': ['general', 'good', 'verygood'],\n 'C': ['no', 'yes']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取训练数据集D\n",
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "# 抽取特征集\n",
    "A = extractFeatures(D)\n",
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0.08300749985576883, 'A2': 0.32365019815155627, 'A3': 0.4199730940219749, 'A4': 0.36298956253708536}\n",
      "选择特征 A3 作为最优特征，其信息增益为0.42\n"
     ]
    }
   ],
   "source": [
    "# 计算各个特征的信息增益\n",
    "bestName, bestValue = selectBestFeatures(D, A)\n",
    "print(\"选择特征 {0} 作为最优特征，其信息增益为{1}\".format(bestName, round(bestValue, 4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 决策树的生成\n",
    "### 例 5.3 对下表中的训练数据集，利用ID3算法建立决策树\n",
    "![](http://qiniu.lianghao.work/markdown/20220505100016.png)\n",
    "生成的ID3决策树如下所示\n",
    "![](http://qiniu.lianghao.work/markdown/20220505202110.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def divDataSet(D, Feature, bestName):\n",
    "    featureId = 0\n",
    "    for key in Feature.keys():\n",
    "        if key == bestName:\n",
    "            break\n",
    "        featureId += 1\n",
    "    # div features\n",
    "    divD = dict()\n",
    "    for key in Feature[bestName]:\n",
    "        tmp = []\n",
    "        for i in range(0, len(D)):\n",
    "            if D[i][featureId] == key:\n",
    "                D[i].pop(featureId)\n",
    "                tmp.append(D[i])\n",
    "        divD[key] = tmp\n",
    "    Feature.pop(bestName)\n",
    "    return divD, Feature\n",
    "\n",
    "def sampleClass(D):\n",
    "    clc = dict()\n",
    "    cid = len(D[0]) - 1\n",
    "    for i in range(0, len(D)):\n",
    "        if D[i][cid] not in clc:\n",
    "            clc[D[i][cid]] = 1\n",
    "        else:\n",
    "            clc[D[i][cid]] += 1\n",
    "    return clc\n",
    "\n",
    "def sameClass(D):\n",
    "    clc = sampleClass(D)\n",
    "    if len(clc.keys()) == 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def label(D):\n",
    "    clc = sampleClass(D)\n",
    "    maxn = ''\n",
    "    maxv = 0\n",
    "    for key, value in clc.items():\n",
    "        if maxv < value:\n",
    "            maxv = value\n",
    "            maxn = key\n",
    "    return maxn, maxv\n",
    "\n",
    "def showTree(parent, tree):\n",
    "    if tree == None:\n",
    "        return\n",
    "    print(parent, ' -- ', tree.relation, '  --', tree.value)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        showTree(tree.value, tree.children[i])\n",
    "\n",
    "def MakeGraph(parent, tree, g, idx):\n",
    "    if tree == None:\n",
    "        return\n",
    "    if idx > 1:\n",
    "        if 'A' not in tree.value:\n",
    "            g.node(name=parent+\" \"+tree.value)\n",
    "            g.edge(parent, parent+\" \"+tree.value, tree.relation)\n",
    "        else:\n",
    "            g.node(name=tree.value)\n",
    "            g.edge(parent, tree.value, tree.relation)\n",
    "    for i in range(0, len(tree.children)):\n",
    "        MakeGraph(tree.value, tree.children[i], g, idx + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decision:\n",
    "    def __init__(self, value, relation):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        self.relation = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def ID3Tree(D, Feature, relation):\n",
    "    if sameClass(D) or len(Feature) == 1:\n",
    "        name, value = label(D)\n",
    "        return Decision(value=name, relation=relation)\n",
    "\n",
    "    bestName, bestValue = selectBestFeatures(D, Feature)\n",
    "    node = Decision(bestName, relation)\n",
    "    divd, divf = divDataSet(D, Feature, bestName)\n",
    "    Keys = [key for key in divd.keys()]\n",
    "    for i in range(0, len(Keys)):\n",
    "        # node.children.append(ID3Tree(divd[Keys[i]], divf, node.value))\n",
    "        node.children.append(ID3Tree(divd[Keys[i]], divf, Keys[i]))\n",
    "    return node\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "A = extractFeatures(D)\n",
    "root = ID3Tree(D, A, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None  --  None   -- A3\n",
      "A3  --  no   -- A2\n",
      "A2  --  no   -- no\n",
      "A2  --  yes   -- yes\n",
      "A3  --  yes   -- yes\n"
     ]
    }
   ],
   "source": [
    "showTree(None, root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'decisionTree.gv.pdf'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "# 创建对象\n",
    "g = Digraph('decisionTree')\n",
    "MakeGraph('start', root, g, 1)\n",
    "g.view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](http://qiniu.lianghao.work/markdown/20220505202110.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.5 CART算法\n",
    "### 5.5.1 CART树生成\n",
    "#### 例 5.4\n",
    "根据下表给定的训练数据集，应用**CART算法**生成决策树\n",
    "![](http://qiniu.lianghao.work/markdown/20220505100016.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def giNi(D):\n",
    "    \"\"\"计算Gini熵\"\"\"\n",
    "    clc = sampleClass(D)\n",
    "    N = len(D)\n",
    "    sum = 0.0\n",
    "    for key, value in clc.items():\n",
    "        sum += (value / N) ** 2\n",
    "    gini = 1 - sum\n",
    "    return gini\n",
    "\n",
    "def giniFeatureValue(D, FeatureId, FeatureValue):\n",
    "    \"\"\"根据特征A和其可能的值a计算其基尼指数\"\"\"\n",
    "    d1, d2 = [], []\n",
    "    for i in range(0, len(D)):\n",
    "        if D[i][FeatureId] == FeatureValue:\n",
    "            d1.append(D[i])\n",
    "        else:\n",
    "            d2.append(D[i])\n",
    "    gini = (len(d1) / len(D)) * giNi(d1) + (len(d2) / len(D)) * giNi(d2)\n",
    "    return gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def giniFeature(D, Features, FeatureName):\n",
    "    \"\"\"找到某一特征内的最优切分点\"\"\"\n",
    "    featureId = 0\n",
    "    for key in Features.keys():\n",
    "        if key == FeatureName:\n",
    "            break\n",
    "        featureId += 1\n",
    "    alpha = ''\n",
    "    maxgini = 1e10\n",
    "    for key in Features[FeatureName]:\n",
    "        gini = giniFeatureValue(D, featureId, key)\n",
    "        if maxgini > gini:\n",
    "            maxgini = gini\n",
    "            alpha = key\n",
    "    return maxgini, alpha\n",
    "\n",
    "def selectBest(D, Features):\n",
    "    \"\"\"找到最优特征和最优切分点\"\"\"\n",
    "    minName = ''\n",
    "    mingni = 1e10\n",
    "    alpha = ''\n",
    "    for featurName in Features.keys():\n",
    "        if featurName != 'C':\n",
    "            gini, nodeName = giniFeature(D, Features, featurName)\n",
    "            if mingni > gini:\n",
    "                minName = featurName\n",
    "                mingni = gini\n",
    "                alpha = nodeName\n",
    "    return minName, alpha, mingni"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "D = readCsv('G:/LiangHao/Master/Learning/MachineLearning/test.csv')\n",
    "Features = extractFeatures(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "('A3', 'no', 0.26666666666666666)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectBest(D, Features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}